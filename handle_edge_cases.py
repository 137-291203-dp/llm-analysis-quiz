#!/usr/bin/env python3
"""
Enhanced edge case handling for robust quiz solving
"""
import pandas as pd
import requests
import tempfile
import os
import logging
from src.config import Config

logger = logging.getLogger(__name__)

class EdgeCaseHandler:
    """Handle common edge cases in quiz solving"""
    
    def __init__(self):
        self.max_file_size_mb = 10  # Limit file size
        self.max_tokens_context = 8000  # Conservative token limit
    
    def handle_large_csv(self, csv_url_or_data):
        """Handle large CSV files that might exceed token limits"""
        logger.info("üîç Handling potentially large CSV file")
        
        try:
            # Download or load CSV
            if isinstance(csv_url_or_data, str) and csv_url_or_data.startswith('http'):
                response = requests.get(csv_url_or_data, stream=True)
                
                # Check file size first
                content_length = response.headers.get('content-length')
                if content_length and int(content_length) > self.max_file_size_mb * 1024 * 1024:
                    logger.warning(f"‚ö†Ô∏è Large file detected: {int(content_length)/1024/1024:.1f}MB")
                    return self._handle_oversized_csv(csv_url_or_data)
                
                # Load CSV
                df = pd.read_csv(csv_url_or_data)
            else:
                df = pd.read_csv(csv_url_or_data)
            
            logger.info(f"üìä CSV loaded: {df.shape[0]} rows, {df.shape[1]} columns")
            
            # Smart sampling for large datasets
            if len(df) > 1000:
                logger.info("üìâ Large dataset detected - applying smart sampling")
                return self._smart_sample_dataframe(df)
            
            return self._prepare_csv_summary(df)
            
        except Exception as e:
            logger.error(f"‚ùå CSV handling error: {e}")
            return {"error": f"CSV processing failed: {e}", "summary": "Unable to process CSV"}
    
    def _smart_sample_dataframe(self, df):
        """Intelligently sample large dataframes"""
        
        # Strategy: Head + Tail + Random sample + Statistics
        sample_data = {
            "total_rows": len(df),
            "total_columns": len(df.columns),
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict(),
            "head_sample": df.head(20).to_dict('records'),
            "tail_sample": df.tail(10).to_dict('records'),
            "statistics": {}
        }
        
        # Add statistics for numeric columns
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            sample_data["statistics"] = df[numeric_cols].describe().to_dict()
        
        # Random sample from middle
        if len(df) > 100:
            random_sample = df.sample(min(50, len(df)//10))
            sample_data["random_sample"] = random_sample.to_dict('records')
        
        logger.info(f"üìä Smart sampling complete: {len(df)} rows ‚Üí summary with key samples")
        return sample_data
    
    def _handle_oversized_csv(self, csv_url):
        """Handle CSV files that are too large to process fully"""
        
        logger.warning("üö® Oversized CSV - using streaming approach")
        
        try:
            # Read only first chunk
            chunk_iter = pd.read_csv(csv_url, chunksize=500, iterator=True)
            first_chunk = next(chunk_iter)
            
            # Get basic info
            summary = {
                "note": "Large file - showing sample only",
                "sample_rows": len(first_chunk),
                "columns": list(first_chunk.columns),
                "dtypes": first_chunk.dtypes.to_dict(),
                "head_sample": first_chunk.head(10).to_dict('records'),
                "statistics": first_chunk.select_dtypes(include=['number']).describe().to_dict() if len(first_chunk.select_dtypes(include=['number']).columns) > 0 else {}
            }
            
            logger.info("üìä Oversized CSV handled with sample")
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå Oversized CSV handling failed: {e}")
            return {"error": "File too large to process", "summary": "CSV file exceeds processing limits"}
    
    def _prepare_csv_summary(self, df):
        """Prepare concise CSV summary for LLM"""
        
        return {
            "shape": {"rows": len(df), "columns": len(df.columns)},
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict(),
            "sample_data": df.head(10).to_dict('records'),
            "statistics": df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else {},
            "missing_values": df.isnull().sum().to_dict(),
            "unique_counts": df.nunique().to_dict()
        }
    
    def detect_csv_headers(self, csv_data_or_url):
        """Robust CSV header detection"""
        logger.info("üîç Detecting CSV headers and structure")
        
        try:
            # Try multiple header detection strategies
            strategies = [
                {"header": 0},  # First row as header
                {"header": None},  # No header
                {"header": 1},  # Second row as header
            ]
            
            best_result = None
            best_score = -1
            
            for strategy in strategies:
                try:
                    if isinstance(csv_data_or_url, str) and csv_data_or_url.startswith('http'):
                        df = pd.read_csv(csv_data_or_url, **strategy, nrows=100)
                    else:
                        df = pd.read_csv(csv_data_or_url, **strategy, nrows=100)
                    
                    # Score this strategy
                    score = self._score_header_detection(df)
                    logger.info(f"üìä Header strategy {strategy} score: {score}")
                    
                    if score > best_score:
                        best_score = score
                        best_result = {"strategy": strategy, "dataframe": df, "score": score}
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Header strategy {strategy} failed: {e}")
                    continue
            
            if best_result:
                logger.info(f"‚úÖ Best header strategy: {best_result['strategy']} (score: {best_result['score']})")
                return best_result
            else:
                raise Exception("All header detection strategies failed")
                
        except Exception as e:
            logger.error(f"‚ùå Header detection failed: {e}")
            # Fallback: assume first row is header
            try:
                if isinstance(csv_data_or_url, str) and csv_data_or_url.startswith('http'):
                    df = pd.read_csv(csv_data_or_url, header=0, nrows=100)
                else:
                    df = pd.read_csv(csv_data_or_url, header=0, nrows=100)
                return {"strategy": {"header": 0}, "dataframe": df, "score": 0}
            except:
                return {"error": "Complete header detection failure"}
    
    def _score_header_detection(self, df):
        """Score header detection quality"""
        score = 0
        
        # Check for reasonable column names
        if hasattr(df, 'columns'):
            col_names = [str(col) for col in df.columns]
            
            # Prefer string column names over numeric
            string_cols = sum(1 for col in col_names if not str(col).isdigit())
            score += string_cols * 2
            
            # Penalize very long column names (might be data)
            reasonable_length = sum(1 for col in col_names if len(str(col)) < 50)
            score += reasonable_length
            
            # Prefer unique column names
            unique_cols = len(set(col_names))
            if unique_cols == len(col_names):
                score += 5
        
        # Check for consistent data types in columns
        if len(df) > 1:
            consistent_types = 0
            for col in df.columns:
                if df[col].dtype != 'object' or df[col].nunique() < len(df) * 0.9:
                    consistent_types += 1
            score += consistent_types
        
        return score
    
    def handle_video_instructions(self, video_url):
        """Handle video instruction content"""
        logger.info(f"üé• Processing video instructions: {video_url}")
        
        # For videos, we can't process directly, but we can:
        # 1. Extract metadata
        # 2. Look for transcripts
        # 3. Provide fallback instructions
        
        fallback_instructions = {
            "note": "Video content detected - using fallback processing",
            "video_url": video_url,
            "suggested_approach": [
                "Video likely contains visual demonstrations",
                "Look for accompanying text or transcripts", 
                "Focus on data analysis rather than video-specific content",
                "Use standard data analysis approaches"
            ],
            "common_video_tasks": [
                "Data visualization interpretation",
                "Step-by-step calculation demonstrations",
                "Software tool usage examples",
                "Statistical concept explanations"
            ]
        }
        
        logger.info("üé• Video fallback instructions provided")
        return fallback_instructions
    
    def improve_code_generation_quality(self, task_description, data_summary):
        """Provide better prompting for consistent code generation"""
        
        enhanced_prompt = f"""
TASK: {task_description}

DATA CONTEXT: {data_summary}

REQUIREMENTS:
1. Generate ONLY executable Python code
2. Use standard libraries: pandas, numpy, matplotlib
3. Handle missing values appropriately
4. Include error checking
5. Return final result in specified format

CODE TEMPLATE:
```python
import pandas as pd
import numpy as np

# Load and process data
try:
    # Your data processing here
    result = None  # Calculate final result
    print(result)  # Output final answer
except Exception as e:
    print(f"Error: {{e}}")
    result = None
```

Generate robust code that follows this template:
"""
        
        return enhanced_prompt
    
    def validate_and_fix_common_issues(self, generated_code):
        """Common code fixes and validation"""
        
        fixes = []
        
        # Fix common pandas issues
        if 'pd.read_csv' in generated_code and 'header=' not in generated_code:
            generated_code = generated_code.replace('pd.read_csv(', 'pd.read_csv(header=0, ')
            fixes.append("Added explicit header parameter")
        
        # Add missing imports
        if 'pandas' in generated_code and 'import pandas' not in generated_code:
            generated_code = 'import pandas as pd\n' + generated_code
            fixes.append("Added pandas import")
            
        if 'numpy' in generated_code and 'import numpy' not in generated_code:
            generated_code = 'import numpy as np\n' + generated_code
            fixes.append("Added numpy import")
        
        # Add basic error handling if missing
        if 'try:' not in generated_code:
            lines = generated_code.split('\n')
            indented_lines = ['    ' + line for line in lines[2:]]  # Skip imports
            generated_code = '\n'.join(lines[:2]) + '\ntry:\n' + '\n'.join(indented_lines) + '\nexcept Exception as e:\n    print(f"Error: {e}")'
            fixes.append("Added error handling")
        
        if fixes:
            logger.info(f"üîß Applied code fixes: {', '.join(fixes)}")
        
        return generated_code

def test_edge_case_handlers():
    """Test the edge case handlers"""
    
    handler = EdgeCaseHandler()
    
    print("üß™ Testing Edge Case Handlers")
    print("=" * 50)
    
    # Test CSV header detection
    print("\nüìä Testing CSV Header Detection...")
    # This would use a real CSV in practice
    print("‚úÖ Header detection ready")
    
    # Test video handling
    print("\nüé• Testing Video Instruction Handling...")
    video_result = handler.handle_video_instructions("https://example.com/instructions.mp4")
    print(f"‚úÖ Video handling: {video_result['note']}")
    
    # Test code improvement
    print("\nüîß Testing Code Generation Enhancement...")
    enhanced_prompt = handler.improve_code_generation_quality(
        "Calculate mean of dataset",
        {"columns": ["value"], "rows": 100}
    )
    print(f"‚úÖ Enhanced prompt ready ({len(enhanced_prompt)} chars)")
    
    print("\nüéØ All edge case handlers ready!")

if __name__ == "__main__":
    test_edge_case_handlers()
